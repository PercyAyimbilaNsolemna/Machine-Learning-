{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a model for recognizing a handwritten digit from 0 to 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "\n",
    "Imports the below listed libraries\n",
    "\n",
    "- Numpy \n",
    "- Matplotlib\n",
    "- TensorFlow\n",
    "- Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads the handwritten data \n",
    "\n",
    "Loads the handwritten data from http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "This is the MNIST handwritten digit dataset (http://yann.lecun.com/exdb/mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dta is (5000, 400)\n",
      "The shape of the target values is (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loads the training data\n",
    "X = np.load('../Binary_Handwritten_Recognition/Data/X.npy')\n",
    "print(f'The shape of the training dta is {X.shape}')\n",
    "\n",
    "# Loads the target values\n",
    "y = np.load('../Binary_Handwritten_Recognition/Data/y.npy')\n",
    "print(f'The shape of the target values is {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "This outputs few of the training examples and the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first few training examples are \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "The first five target values are \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(f'The first few training examples are \\n {X[:5]}')\n",
    "\n",
    "print(f'The first five target values are \\n {y[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting \n",
    "\n",
    "This ssplits the data into train, cross validation(cv) and test set.\n",
    "\n",
    "The train set will be used to train the model\n",
    "\n",
    "The cross validation set will be used to validate the parameters gained from the train set to minimize variance(overfitting) or bias(underfitting). \n",
    "\n",
    "The test set will be used to test the model chosen after cross validation. \n",
    "\n",
    "40% train set, 20% cross validation(cv) set and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape  of the training data is (3000, 400)\n",
      "The shape of the target values is (3000, 1) \n",
      "\n",
      "The shape of the cross validation data is (1000, 400)\n",
      "The shape of the cross validation target values is (1000, 1) \n",
      "\n",
      "The shape of the test training data is (1000, 400)\n",
      "The shape of the test set target value is (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "#help(train_test_split)\n",
    "#This splits the data into train set and X_ and y_ which will inturn be subdided into cross validation and test set\n",
    "X_train, X_, y_train, y_ = train_test_split(X, y, train_size=0.6)\n",
    "print(f'The shape  of the training data is {X_train.shape}')\n",
    "print(f'The shape of the target values is {y_train.shape} \\n')\n",
    "\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_, y_, test_size=0.5)\n",
    "print(f'The shape of the cross validation data is {X_cv.shape}')\n",
    "print(f'The shape of the cross validation target values is {y_cv.shape} \\n')\n",
    "\n",
    "print(f'The shape of the test training data is {X_test.shape}')\n",
    "print(f'The shape of the test set target value is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "The training data has a shape of 5000 by 400 where 400 represents the features in a 20 by 20 pixels of a handwritten digit.\n",
    "\n",
    "Outputting the 20 by 20 pixels of any of the training data shows the exact handwritten digit\n",
    "\n",
    "The corresponding y value shows the exact handwritten digit for that specific training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
